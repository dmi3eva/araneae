{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AraneaeWrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwSBfWvfb5hyvS9D4k+D9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmi3eva/araneae/blob/main/p3_araneae_wrapper/AraneaeWrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61k2KeVqGQ2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60984624-cd53-4b6c-aa46-b615c6a3c80a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxirzeey0h_8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3_m-GcZ1rit",
        "outputId": "956e27d7-8a2f-4d2d-d9b3-30df2dcb4d76"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fjy9lY0wac",
        "outputId": "0b8614a0-0bbd-4878-abe4-f494bbadd10f"
      },
      "source": [
        "%cd /content\n",
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%cd PhD\n",
        "%cd Paper_01"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/PhD\n",
            "/content/drive/My Drive/PhD/Paper_01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elqns59708LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1dab48-e742-4b90-ed6c-483af493acf3"
      },
      "source": [
        "%cd spider_preprocessing\n",
        "from process_sql import *\n",
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PhD/Paper_01/spider_preprocessing\n",
            "/content/drive/My Drive/PhD/Paper_01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tebEhJuaY5wZ"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnY1mydxcObF"
      },
      "source": [
        "from typing import Dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcL9qHMQY7ww"
      },
      "source": [
        "def unfold_list():\n",
        "  unfolded_list = []\n",
        "  for _value in values:\n",
        "    if isinstance(_value, list):\n",
        "      unfolded_list += unfold_list(_value)\n",
        "    else:\n",
        "      new_value = _value\n",
        "      if isinstance(_value, float) and (int(_value) - _value < 0.01):\n",
        "        new_value = int(value)\n",
        "      unfolded_list.append(new_value)\n",
        "  return unfolded_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVCVPZ3dJQIZ"
      },
      "source": [
        "def preprocess_SQL(sentence, splitter='select'):\n",
        "    sentence = sentence.strip()\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    # Убираем названия (новое)\n",
        "    if ' as ' in sentence.lower():\n",
        "      renaming = {}    \n",
        "      for i, _token in enumerate(tokens):\n",
        "        if _token.lower() == 'as':\n",
        "          sentence = sentence.replace(f'AS {tokens[i + 1]} ', '')\n",
        "          sentence = sentence.replace(tokens[i + 1], tokens[i - 1])\n",
        "    \n",
        "\n",
        "    # Сортируем аргументы SELECT\n",
        "    tokens = sentence.split()\n",
        "    select_part = []\n",
        "    select_tokens = []\n",
        "    before_tokens = []\n",
        "    after_tokens = []\n",
        "    select_flag = 'before'\n",
        "    for _token in tokens:  \n",
        "      if splitter in _token.lower():\n",
        "        select_flag = 'during'\n",
        "        before_tokens.append(_token)\n",
        "      elif select_flag == 'during' and 'from' != _token.lower().strip():\n",
        "        select_tokens.append(_token)\n",
        "      else:\n",
        "        if 'from' in _token.lower().strip():\n",
        "          select_flag = 'after'\n",
        "          after_tokens.append(_token)\n",
        "        elif select_flag == 'after':\n",
        "          after_tokens.append(_token)\n",
        "        else:\n",
        "          before_tokens.append(_token)\n",
        "\n",
        "    select_part = ' '.join(select_tokens)\n",
        "    select_tokens = select_part.split(',')\n",
        "    select_tokens = sorted([_t.strip() for _t in select_tokens])\n",
        "    select_part = ' , '.join(select_tokens)\n",
        "\n",
        "    sentence = \"{} {} {}\".format(' '.join(before_tokens), select_part, ' '.join(after_tokens))\n",
        "\n",
        "    # Убираем названия таблиц, если она одна\n",
        "    if '.' in sentence and not 'join' in sentence.lower():\n",
        "      tokens = sentence.split()          \n",
        "      new_tokens = []\n",
        "      for _token in tokens:  \n",
        "        if '.' in _token:\n",
        "          new_tokens.append(_token.split('.')[1])\n",
        "        else:\n",
        "          new_tokens.append(_token)\n",
        "      sentence = ' '.join(new_tokens)\n",
        "      \n",
        "    result = sentence.replace('* ', '*').replace(' * ', '*').replace(' ,', ',').replace('( ', '(').replace(' )', ')')\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrH0R_0gde4s"
      },
      "source": [
        "DB_PATH = \"datasets/spider/database\"\n",
        "SCHEMES_PATH = \"datasets/spider/tables.json\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMBmQFq7dbyl"
      },
      "source": [
        "with open(SCHEMES_PATH) as table_file:\n",
        "  schemes = json.load(table_file)\n",
        "\n",
        "dbs = {_s['db_id']: _s for _s in schemes}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flhb2qh_dCdc"
      },
      "source": [
        "def extract_column_from_col_unit(scheme, col_unit):\n",
        "  col_id = col_unit[1]\n",
        "  column = scheme[\"column_names_original\"][col_id]\n",
        "  table_id = column[0] \n",
        "  return {\n",
        "      \"db_id\": scheme[\"db_id\"],\n",
        "      \"table\": scheme[\"table_names_original\"][table_id],\n",
        "      \"column\": column[1]\n",
        "  }\n",
        "\n",
        "def extract_column_from_val_unit(scheme, val_unit):\n",
        "  col_unit_1 = val_unit[1]\n",
        "  col_unit_2 = val_unit[2]\n",
        "  columns = [extract_column_from_col_unit(scheme, col_unit_1)]\n",
        "  if col_unit_2: \n",
        "    columns += [extract_column_from_col_unit(scheme, col_unit_2)]\n",
        "  return columns \n",
        "\n",
        "def extract_column_from_table_unit(scheme, table_unit):\n",
        "  if isinstance(table_unit, dict) and 'select' in val:\n",
        "    return get_units_from_spider_sql(scheme['db_id'], table_unit[1])\n",
        "  if isinstance(table_unit[1], tuple) and len(table_unit[1]) == 3: \n",
        "    return extract_column_from_col_unit(scheme, table_unit[1])\n",
        "  return []\n",
        "\n",
        "def extract_column_from_cond_unit(scheme, table_unit):\n",
        "  units = []\n",
        "  units += extract_column_form_val_unit(scheme, table_unit[2])\n",
        "  units += extract_column_form_val(scheme, table_unit[3])\n",
        "  units += extract_column_form_val(scheme, table_unit[4])\n",
        "  return units\n",
        "\n",
        "def extract_column_from_val(scheme, val):\n",
        "  if isinstance(val, dict) and 'select' in val:\n",
        "    return get_units_from_spider_sql(scheme['db_id'], val)\n",
        "  return []\n",
        "\n",
        "def extract_column_from_condition(scheme, condition):\n",
        "  units = []\n",
        "  conditions_amount = len(condition) // 2\n",
        "  for i in range(conditions_amount):\n",
        "    units += extract_column_from_cond_unit(scheme, condition[2 * i])\n",
        "  return units  \n",
        "\n",
        "def deduplicate(list_of_dict):\n",
        "  deduplicated = []\n",
        "  hashes = []\n",
        "  for _dict in list_of_dict:\n",
        "    dict_hash = [f\"{_k}:{_v}\" for _k, _v in _dict.items()]\n",
        "    if dict_hash not in hashes:\n",
        "      deduplicated.append(_dict)\n",
        "      hashes.append(dict_hash)\n",
        "  return deduplicated\n",
        "\n",
        "\n",
        "def get_units_from_spider_sql(db_id: str, sql: dict):\n",
        "  units = []  \n",
        "  scheme = dbs[db_id]\n",
        "  # Parsing of SELECT\n",
        "  for select_unit in sql['select'][1]:\n",
        "    val_unit = select_unit[1]\n",
        "    units += extract_column_from_val_unit(scheme, val_unit)\n",
        "  from_table_units = sql['from']['table_units'] \n",
        "  from_condition = sql['from']['conds']\n",
        "  for _table_unit in from_table_units:\n",
        "    units += extract_column_from_table_unit(scheme, _table_unit)\n",
        "  units += extract_column_from_condition(scheme, from_condition)\n",
        "  units += extract_column_from_condition(scheme, sql['where'])  \n",
        "  for _group in sql['groupBy']:\n",
        "    units += extract_column_from_col_unit(scheme, _group)\n",
        "  if isinstance(sql['orderBy'], tuple) and len(sql['orderBy']) >= 2:\n",
        "    for _val in sql['orderBy'][1]:\n",
        "      units += extract_column_from_val_unit(scheme, _val)\n",
        "  units += extract_column_from_condition(scheme, sql['having']) \n",
        "  if sql['intersect']:\n",
        "    units += get_units_from_spider_sql(db_id, sql['intersect'])\n",
        "  if sql['except']:\n",
        "    units += get_units_from_spider_sql(db_id, sql['except'])\n",
        "  if sql['union']:\n",
        "    units += get_units_from_spider_sql(db_id, sql['union'])\n",
        "  return deduplicate(units)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7NaTK3cC1F"
      },
      "source": [
        "def get_units_from_sample(sample: dict):\n",
        "  db_id = sample['db_id']\n",
        "  return get_units_from_spider_sql(db_id, sample['sql'])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1RlQ6CfcZrN"
      },
      "source": [
        "with open('datasets/araneae/araneae.json') as table_file:\n",
        "  araneae = json.load(table_file)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ui5gE5YajxnL",
        "outputId": "332660a4-a7b0-4a66-be65-2335f28e141e"
      },
      "source": [
        "sample = araneae[29]\n",
        "sample['question']"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What are the names of the stadiums without any concerts?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xTai7Iz8j762",
        "outputId": "0b6e31c2-83d6-4120-da58-42ffa55aa1ce"
      },
      "source": [
        "sample['query']"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYEsPuXmkMOd",
        "outputId": "05bd0398-463e-43d9-beb0-0fa283c798e9"
      },
      "source": [
        "dbs['concert_singer'][\"table_names_original\"]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stadium', 'singer', 'concert', 'singer_in_concert']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYbAAOAwzKWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1461fae6-b051-4a77-e4b5-c9aea699ecfd"
      },
      "source": [
        "units = get_units_from_sample(sample)\n",
        "units"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'column': 'Name', 'db_id': 'concert_singer', 'table': 'stadium'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8QGhl1Dnmrq",
        "outputId": "3272d537-5669-4666-da93-f72cf24be092"
      },
      "source": [
        "sample['sql']['select'][1]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, [0, [0, 9, False], None]],\n",
              " [0, [0, [0, 10, False], None]],\n",
              " [0, [0, [0, 13, False], None]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LZtBKMZF9Qc"
      },
      "source": [
        "### Main class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpooXPHGXSKM"
      },
      "source": [
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from typing import Tuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FPgcdSxXZ-O"
      },
      "source": [
        "with open('datasets/araneae/binary_values.json') as table_file:\n",
        "  binary_classification = json.load(table_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fReLyDcSFWvj"
      },
      "source": [
        "class AraneaeWrapper:\n",
        "  def __init__(self, samples_path, tables_path, db_path):\n",
        "    self.samples = []\n",
        "    self.db_path = db_path\n",
        "    with open(samples_path) as sample_file:\n",
        "      self.samples = json.load(sample_file)\n",
        "    with open(tables_path) as tables_file:\n",
        "      self.tables = json.load(tables_file)\n",
        "    for _sample in self.samples:\n",
        "      _sample = self.augment_sample(_sample)\n",
        "\n",
        "  def augment_sample(self, sample):\n",
        "    if 'description' not in sample.keys():\n",
        "      sample['description'] = {}\n",
        "    if 'tags' not in sample.keys():\n",
        "      sample['tags'] = []    \n",
        "    if 'question_toks' not in sample.keys():\n",
        "      sample['question_toks'] = tokenize(sample['question'])      \n",
        "    \n",
        "    if 'sql' not in sample.keys():\n",
        "      db_id = sample['db_id']\n",
        "      db = get_schema(f\"{self.db_path}/{db_id}/{db_id}.sqlite\")\n",
        "      schema = Schema(db)\n",
        "      sql_dict = get_sql(schema, sample['query'])\n",
        "      sample['sql'] = sql_dict\n",
        "      query_no_value = sample['query']\n",
        "      for _value in unfold_list(sql_dict['where']):\n",
        "        if str(_value) in query_no_value:\n",
        "          query_no_value = query_no_value.replace(str(_value), 'value')\n",
        "      sample['question_toks_no_value'] = tokenize(query_no_value)\n",
        "      \n",
        "    augmented_sample = deepcopy(sample)\n",
        "    augmented_sample = self.add_nl_tag(augmented_sample)\n",
        "    return augmented_sample\n",
        "\n",
        "  def add_nl_tag(self, sample):\n",
        "    SHORT_THRESHOLD = 13\n",
        "    LONG_THRESHOLD = 17\n",
        "    if 'NL-length' in sample['description']:\n",
        "      return sample\n",
        "    tag = None\n",
        "    augmented_sample = deepcopy(sample)\n",
        "    request_len = len(sample['question_toks'])\n",
        "    if request_len <= SHORT_THRESHOLD:\n",
        "      tag = \"NL-short\"\n",
        "    elif request_len <= LONG_THRESHOLD:\n",
        "      tag = \"NL-avg\"\n",
        "    else:\n",
        "      tag = \"NL-long\"\n",
        "    augmented_sample['tags'].append(tag)\n",
        "    augmented_sample['description']['NL-length'] = tag\n",
        "    return augmented_sample\n",
        "\n",
        "  def add_binary_tag(self, sample):\n",
        "    db_id = sample[\"db_id\"]\n",
        "    \n",
        "  def get_samples_with_tag(self, tag):\n",
        "    samples_with_tag = [_s for _s in self.samples if tag in _s['tags']]\n",
        "    return samples_with_tag\n",
        "\n",
        "  def add_sample(self, nl, db_id, sql, source, tag=None, description: Tuple[str, str]=(None, None)):\n",
        "    new_sample = {\n",
        "        'db_id': db_id,\n",
        "        'question': nl,\n",
        "        'source': source,\n",
        "        'query': preprocess_SQL(sql),\n",
        "        'tags': [],\n",
        "        'description': {}\n",
        "    }   \n",
        "    print(new_sample) \n",
        "    if tag:\n",
        "      new_sample['tags'].append(tag)\n",
        "    if description[0] and description[1]:\n",
        "      new_sample['description'][description[0]] = description[1]\n",
        "    new_sample = self.augment_sample(new_sample)\n",
        "    self.samples.append(new_sample)\n",
        "\n",
        "  def add_samples_from_csv(self, file_path, tag=None, description: Tuple[str, str]=(None, None)):\n",
        "    new_samples = pd.read_csv(file_path)\n",
        "    for ind, row in new_samples.iterrows():\n",
        "      self.add_sample(row['nl'], row['db_id'], row['sql'], file_path, tag=tag, description=description)\n",
        "\n",
        "  def save_in_json(self, file_path):\n",
        "    with open(file_path, 'w') as json_file:\n",
        "      json.dump(self.samples, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KCtbI8hs6Lk"
      },
      "source": [
        "### Spider preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEYVKSw-ttcs",
        "outputId": "2f177644-a041-488f-b13f-34fa2f2305ed"
      },
      "source": [
        "%cd /content\n",
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%cd PhD\n",
        "%cd Paper_01\n",
        "%cd spider_preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/PhD\n",
            "/content/drive/My Drive/PhD/Paper_01\n",
            "/content/drive/My Drive/PhD/Paper_01/spider_preprocessing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtVLm-7js61c",
        "outputId": "aa2f9aba-26bb-4b65-8518-1028baf041a1"
      },
      "source": [
        "!git clone https://github.com/taoyds/spider"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'spider'...\n",
            "remote: Enumerating objects: 380, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 380 (delta 8), reused 0 (delta 0), pack-reused 361\u001b[K\n",
            "Receiving objects: 100% (380/380), 44.95 MiB | 15.96 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "Checking out files: 100% (261/261), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov841oxKF_9C"
      },
      "source": [
        "### Тест"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RknGfWOLaI_E",
        "outputId": "ecb5bd18-bc0a-40ec-bf70-45d1d6c89e4a"
      },
      "source": [
        "%cd /content\n",
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%cd PhD\n",
        "%cd Paper_01"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/PhD\n",
            "/content/drive/My Drive/PhD/Paper_01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6yQvL4_aPdT"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8KUnQCoaQPK"
      },
      "source": [
        "araneae = AraneaeWrapper(\"datasets/araneae/araneae.json\", \"datasets/spider/tables.json\", \"datasets/spider/database\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwYc2HD2-2ly"
      },
      "source": [
        "araneae.add_samples_from_csv(\"datasets/to_add/binary_values.csv\", tag='binary-values', description=('values', 'containing-binary'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HWdoWlgd46L"
      },
      "source": [
        "araneae.get_samples_with_tag('binary-values')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9egwfes58Ey3"
      },
      "source": [
        "### Tests' zone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AcMr75fRZYW"
      },
      "source": [
        "Tokenization from Spider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8V7jVFfh6ZF",
        "outputId": "8c2604d8-02cb-4f03-bb36-51651f821ed6"
      },
      "source": [
        "tokens = tokenize(\"My dogs is good!\")\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'dogs', 'is', 'good', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdUybcDyRd-0"
      },
      "source": [
        "SQL-processing from Spider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU1uEOT6IAdt",
        "outputId": "8c217e5d-e019-4dd3-d868-fb4921c6e2ad"
      },
      "source": [
        "query = \"SELECT name FROM singer\"\n",
        "schema_sql = get_schema(\"datasets/spider/database/singer/singer.sqlite\")\n",
        "schema = Schema(schema_sql)\n",
        "sql = get_sql(schema, query)\n",
        "sql"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'except': None,\n",
              " 'from': {'conds': [], 'table_units': [('table_unit', '__singer__')]},\n",
              " 'groupBy': [],\n",
              " 'having': [],\n",
              " 'intersect': None,\n",
              " 'limit': None,\n",
              " 'orderBy': [],\n",
              " 'select': (False, [(0, (0, (0, '__singer.name__', False), None))]),\n",
              " 'union': None,\n",
              " 'where': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7eOLiGRiwd"
      },
      "source": [
        "SQL-preprocessing from Araneae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4qzSO0LSRlyU",
        "outputId": "e58f8540-7be5-4863-af1b-20575250c120"
      },
      "source": [
        "sentence = \"SELECT T1.name , zaza, count(*), A FROM concert AS T1 GROUP BY t1.stadium_id\"\n",
        "preprocessed_sql = preprocess_SQL(sentence)\n",
        "preprocessed_sql"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SELECT A, name, count(*), zaza FROM concert GROUP BY stadium_id'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}